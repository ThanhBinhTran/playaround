{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run with Python 3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import shutil\n",
    "import re\n",
    "import os\n",
    "import pathlib\n",
    "import argparse\n",
    "import pdb\n",
    "import threading\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def site_open(site):\n",
    "    '''Makes connection and opens up target website. Returns a website object.'''\n",
    "    try:\n",
    "        #sets up request object\n",
    "        req = urllib.request.Request(site)\n",
    "\n",
    "        #adds User-Agent info to request object\n",
    "        req.add_header(\"User-Agent\",\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_8) \\\n",
    "         AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.46 Safari/536.5\")\n",
    "\n",
    "        #opens up site\n",
    "        website = urllib.request.urlopen(req)\n",
    "\n",
    "        return website\n",
    "    except urllib.request.URLError:\n",
    "#            print('Could not connect to '+ site + '!')\n",
    "           pass\n",
    "    \n",
    "def soup_site(site):\n",
    "    '''opens site and turns it into a format to easily parse the DOM. Returns a Soup Object'''\n",
    "    try:\n",
    "        website = site_open(site)\n",
    "#         return BeautifulSoup(website, \"html5lib\")\n",
    "        return BeautifulSoup(website, \"lxml\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_web_data_from_link(link):\n",
    "    return soup_site(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geting infomation from: http://kinh.kinhphat.org/kinhgiang/NhatHanh/TrinhCongSon/\n",
      "['http://kinh.kinhphat.org/kinhgiang/NhatHanh/TrinhCongSon/TrinhCongSon-1.mp3', 'TrinhCongSon-1.mp3']\n",
      "['http://kinh.kinhphat.org/kinhgiang/NhatHanh/TrinhCongSon/TrinhCongSon-2.mp3', 'TrinhCongSon-2.mp3']\n",
      "['http://kinh.kinhphat.org/kinhgiang/NhatHanh/TrinhCongSon/TrinhCongSon-3.mp3', 'TrinhCongSon-3.mp3']\n"
     ]
    }
   ],
   "source": [
    "links = \"http://hanvota.com/nhac/web/\";\n",
    "links = \"http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock/Take+Me+to+Your+Heart/\"\n",
    "links = \"http://www.dna.com.vn/folder_news/\"\n",
    "links = 'http://kinh.kinhphat.org/kinhgiang/NhatHanh/TrinhCongSon/'\n",
    "print (\"Geting infomation from: \" + links)\n",
    "\n",
    "#file_filter = [\".jpg\", \".gif\", \".jpg\"]\n",
    "file_filter = [\".mp3\"]\n",
    "\n",
    "soup = get_web_data_from_link(links);\n",
    "#print (soup)\n",
    "\n",
    "all_info = []\n",
    "file_name = ''#\n",
    "path = ''\n",
    "\n",
    "\n",
    "if soup != -1:\n",
    "    hyperlink_tags = soup.find_all('a')\n",
    "    \n",
    "    for hyperlink_tag in hyperlink_tags:\n",
    "        #print (hyperlink_tag)\n",
    "        hyperlink = hyperlink_tag.get('href') \n",
    "        hyperlink_value = hyperlink_tag.text\n",
    "        \n",
    "        #print (hyperlink)\n",
    "        for f_filter in file_filter:\n",
    "            if hyperlink.find(f_filter) != -1:      # keep all hyperlinks which contain pattern\n",
    "                #print (\"hyperlink:\" + hyperlink)\n",
    "                downlink = links + hyperlink\n",
    "                if hyperlink.find('/') != -1:     # if hyperlink contains /  then check duplicate in path\n",
    "                    path = hyperlink.rsplit('/', 1)[0]            # get the first part from last /\n",
    "                    #print(\"Path:\" + path)\n",
    "                    if links.find(path) != -1:      # found overlap between links and hyperlink\n",
    "                                                    # then remove overlap\n",
    "                        downlink = downlink.replace(path, '',1)\n",
    "                #print (downlink)\n",
    "\n",
    "                if hyperlink_value.find(f_filter) != -1:  # if filename already provided, use it\n",
    "                    file_name = hyperlink_value\n",
    "                    #print(\"test: \" + test)\n",
    "                else:                                        # else create new 1 from the hyperlink\n",
    "                    if hyperlink.find('/') != -1:     # if hyperlink contains /  then get the last field (name)\n",
    "                        file_name = hyperlink.rsplit('/', 1)[1]\n",
    "                    else:                             # else file name is same hyperlink\n",
    "                        file_name = hyperlink     \n",
    "                all_info.append([downlink, file_name])\n",
    "for item in all_info:\n",
    "    print (item)\n",
    "#print (all_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading: http://kinh.kinhphat.org/kinhgiang/NhatHanh/TrinhCongSon/TrinhCongSon-1.mp3\n",
      "downloading: http://kinh.kinhphat.org/kinhgiang/NhatHanh/TrinhCongSon/TrinhCongSon-2.mp3\n",
      "downloading: http://kinh.kinhphat.org/kinhgiang/NhatHanh/TrinhCongSon/TrinhCongSon-3.mp3\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# mode \n",
    "mode = 0o666\n",
    "# check if download folder is exist\n",
    "isdir = os.path.isdir(\"download\")\n",
    "if  not isdir:  # if not create new one\n",
    "    os.mkdir(\"download\", mode) \n",
    "\n",
    "for item in all_info:\n",
    "    print('Downloading: ' + item[0])\n",
    "    urllib.request.urlretrieve(item[0], \"download\\\\\" +item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv file\n",
    "import csv\n",
    "f = open(\"all_links.csv\", 'w', newline='', encoding=\"utf-8\")\n",
    "writer = csv.writer(f, delimiter=\",\")\n",
    "writer.writerow([\"link\", \"file name\"])\n",
    "for item in all_info:\n",
    "    writer.writerow(item)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geting infomation from: http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock/\n",
      "hyperl      ink.findhttp://9806.unknownsecret.info/mp3/Valerio+Cosi\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock/http://9806.unknownsecret.info/mp3/Valerio+Cosi/\n",
      "hyperl      ink.findhttp://1066.unknownsecret.info/mp3/DJ+Tatana+%26+DJ+Energy\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock/http://1066.unknownsecret.info/mp3/DJ+Tatana+%26+DJ+Energy/\n",
      "hyperl      ink.findhttp://9347.unknownsecret.info/mp3/Stijn+Moekaars+gelesen+von+Nina+Petri\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock/http://9347.unknownsecret.info/mp3/Stijn+Moekaars+gelesen+von+Nina+Petri/\n",
      "hyperl      ink.findhttp://9201.unknownsecret.info/mp3/Our+Helical+Mind\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock/http://9201.unknownsecret.info/mp3/Our+Helical+Mind/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/..\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/../\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/Greatest+Hits\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/Greatest+Hits/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/Michael+Learns+to+Rock\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/Michael+Learns+to+Rock/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/Take+Me+to+Your+Heart\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/Take+Me+to+Your+Heart/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/25%3A+The+Complete+Singles\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/25%3A+The+Complete+Singles/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/Colours\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/Colours/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/Eternity\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/Eternity/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/Upon+a+Christmas+Night\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/Upon+a+Christmas+Night/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/With+Love\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/With+Love/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/Strange+Foreign+Beauty\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/Strange+Foreign+Beauty/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/Take+Me+to+Your+Heart+%28Trance+Version%29\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/Take+Me+to+Your+Heart+%28Trance+Version%29/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/Paint+My+Love\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/Paint+My+Love/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/One+More+Minute\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/One+More+Minute/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/Nothing+to+Lose\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/Nothing+to+Lose/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/Paint+My+Love%3A+Greatest+Hits\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/Paint+My+Love%3A+Greatest+Hits/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/Michael+Learns+To+Rock+-+Greatest+Hits+%5BAsian+Tour+Limited+Edition%5D+CD2\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/Michael+Learns+To+Rock+-+Greatest+Hits+%5BAsian+Tour+Limited+Edition%5D+CD2/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/19+Love+Ballads\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/19+Love+Ballads/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/19+Love+Songs\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/19+Love+Songs/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/Strange+Foreign+Beauty+-+Remixed+%26+More\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/Strange+Foreign+Beauty+-+Remixed+%26+More/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/Wild+Women\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/Wild+Women/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/Scandinavia\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/Scandinavia/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/The+Best+Of+Michael+Learns+To+Rock+Live\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/The+Best+Of+Michael+Learns+To+Rock+Live/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/Played+on+Pepper\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/Played+on+Pepper/\n",
      "hyperl      ink.find/mp3/Michael+Learns+to+Rock/Blue+Night\n",
      "http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock//mp3/Michael+Learns+to+Rock/Blue+Night/\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n",
      "object of type 'NoneType' has no len()\n"
     ]
    }
   ],
   "source": [
    "# this function will list all links as posible of a website\n",
    "link = 'http://kinh.kinhphat.org/kinhgiang/NhatHanh/'\n",
    "link = \"http://1506.unknownsecret.info/mp3/Michael+Learns+to+Rock/\"\n",
    "print (\"Geting infomation from: \" + link)\n",
    "\n",
    "all_links = []\n",
    "all_links.append(link)\n",
    "for cur_link in all_links:\n",
    "    # check if current link is a file. \n",
    "    if cur_link[-1] == '/':   # process if current link is folder, skip if it's a file\n",
    "        soup = get_web_data_from_link(cur_link);\n",
    "        if soup != -1:  # handle if data is responded\n",
    "            hyperlink_tags = soup.find_all('a')\n",
    "            for hyperlinks in hyperlink_tags:\n",
    "                hyperlink = hyperlinks.get('href')\n",
    "                downlink = cur_link + hyperlink\n",
    "                if hyperlink.find('/') != -1:     # if hyperlink contains /  then check duplicate in path\n",
    "                    \n",
    "                    path = hyperlink.rsplit('/', 1)[0]            # get the first part from last /\n",
    "                    print (\"hyperl      ink.find\" + path)\n",
    "                    if cur_link.find(path) != -1:      # found overlap between links and hyperlink\n",
    "                                                    # then remove overlap\n",
    "                        print (\"hyperl      ink.find replace\")\n",
    "                        downlink = downlink.replace(path, '',1)\n",
    "                print (downlink)\n",
    "                if downlink not in all_links: # not exist in list, then add into it\n",
    "                    # skip if its parrent folder\n",
    "                    #print(\"found: \" + hyperlink)\n",
    "                    if hyperlink.find('../') == -1:\n",
    "                        all_links.append(downlink)\n",
    "                        #print (\"Added: \" + hyperlink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"all_path_site.txt\", \"w\")\n",
    "for site_path in all_links:\n",
    "    f.write(site_path + '\\n');\n",
    "f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
